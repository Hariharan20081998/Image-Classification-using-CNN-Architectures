{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "coil-vgg19.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DeI_3ffbKXG",
        "trusted": true
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import itertools\n",
        "import fnmatch\n",
        "import random\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfdb\n",
        "import keras\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "from keras.engine import Model\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t368M_Imb3n1",
        "trusted": true
      },
      "source": [
        "from glob import glob\n",
        "train = glob('../input/coil100/coil-100/coil-100/*.png', recursive=True)\n",
        "import math\n",
        "from math import floor\n",
        "x = []\n",
        "y = []\n",
        "WIDTH = 128\n",
        "HEIGHT = 128\n",
        "for img in train:\n",
        "    filename = os.path.basename(img)\n",
        "    label = floor( int(filename.split('__')[0][3:]))\n",
        "    y.append(label)\n",
        "for img in train:\n",
        "    full_size_image = cv2.imread(img)\n",
        "    x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n",
        "X= np.array(x)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
        "y_trainHot = to_categorical( Y_train, num_classes = 101)\n",
        "y_testHot = to_categorical( Y_test, num_classes = 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQMKsF3ECXlJ",
        "trusted": true,
        "outputId": "5e81b85a-70e3-4e80-ce3a-879f0e728885"
      },
      "source": [
        "base_model = keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape=(128,128, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oacjtqf0CfVV",
        "trusted": true
      },
      "source": [
        "last = base_model.get_layer('block5_pool').output\n",
        "# Add classification layers on top of it\n",
        "x = BatchNormalization()\n",
        "x = Flatten()(last)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "pred = Dense(101, activation='softmax')(x)\n",
        "\n",
        "model =Model(base_model.input, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaFPtHiiC-cV",
        "trusted": true
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xx_r_ezDClC",
        "trusted": true
      },
      "source": [
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpbdg9iYDKWp",
        "trusted": true
      },
      "source": [
        "history = model.fit(X_train, y_trainHot, epochs=20, batch_size=128, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS8upiIRsnPV",
        "trusted": true
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,y_testHot)\n",
        "print(\"Test Loss: \", test_loss*100)\n",
        "print(\"Test Accuracy: \", test_acc*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zGfb_ijvUfE",
        "trusted": true
      },
      "source": [
        "# Plotting Model Accuracy\n",
        "\n",
        "plt.plot(history.history['acc'], 'blue')\n",
        "plt.plot(history.history['val_acc'], 'orange')\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validate'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ruKHbDvUkF",
        "trusted": true
      },
      "source": [
        "print(\"VGG -Validation Loss: \", history.history['val_loss'][-1]*100)\n",
        "print(\"VGG - Validation Accuracy: \", history.history['val_acc'][-1]*100)\n",
        "print(\"\\n\")\n",
        "print(\"VGG - Training Loss: \", history.history['loss'][-1]*100)\n",
        "print(\"VGG - Training Accuracy: \", history.history['acc'][-1]*100)\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Jnbt0uvUdg",
        "trusted": true
      },
      "source": [
        "# Plotting Model Loss\n",
        "\n",
        "plt.plot(history.history['loss'], 'blue')\n",
        "plt.plot(history.history['val_loss'], 'orange')\n",
        "plt.title(\"Model Loss for VGGNet\")\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validate'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a62E9K0k7sWi"
      },
      "source": [
        "# Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuVk8snj8VIk",
        "trusted": true
      },
      "source": [
        "target_names = []\n",
        "for i in range(100):\n",
        "    a = 'Object '\n",
        "    b = str(i)\n",
        "    c = a+b\n",
        "    c = [i]\n",
        "    target_names.append((a+b))\n",
        "\n",
        "def reports(X_test,y_test):\n",
        "    Y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
        "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "    Test_Loss = score[0]*100\n",
        "    Test_accuracy = score[1]*100\n",
        "    kc=cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
        "    return classification, confusion, Test_Loss, Test_accuracy ,kc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP97Tkzn7wwD",
        "trusted": true
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,cohen_kappa_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score\n",
        "# calculate result, loss, accuray and confusion matrix\n",
        "classification, confusion, Test_loss, Test_accuracy,kc = reports(X_test,y_testHot)\n",
        "classification = str(classification)\n",
        "confusion_str = str(confusion)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ASeTPx9I5V",
        "trusted": true
      },
      "source": [
        "print(\"confusion matrix: \")\n",
        "print('{}'.format(confusion_str))\n",
        "print(\"KAppa Coeefecient=\",kc)\n",
        "print('Test loss {} (%)'.format(Test_loss))\n",
        "print('Test accuracy {} (%)'.format(Test_accuracy))\n",
        "print(classification)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}